{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJNoGoDpcZJtYvlGrlnpzX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By3CIbG3BhJI",
        "outputId": "565c1b61-0e46-4da3-ccc2-60a29a8b59a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Probabilities (h1_p) after training:\n",
            " tensor([[0.0793, 0.2063, 0.0666,  ..., 0.8824, 0.7743, 0.0461],\n",
            "        [0.0723, 0.4369, 0.0457,  ..., 0.9365, 0.8294, 0.2102],\n",
            "        [0.3414, 0.2759, 0.0851,  ..., 0.9474, 0.8797, 0.2034],\n",
            "        ...,\n",
            "        [0.4538, 0.0902, 0.1899,  ..., 0.7619, 0.9514, 0.0483],\n",
            "        [0.1530, 0.7704, 0.1735,  ..., 0.9808, 0.5619, 0.1016],\n",
            "        [0.1556, 0.0370, 0.3908,  ..., 0.9281, 0.8220, 0.7774]],\n",
            "       grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# DEEP BOLTZMAN MACHINE (DBM)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "class DBM(nn.Module):\n",
        "    def __init__(self, vis_dim=784, hid_dims=[512, 256]):\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Parameter(torch.randn(vis_dim, hid_dims[0]) * 0.1)\n",
        "        self.W2 = nn.Parameter(torch.randn(hid_dims[0], hid_dims[1]) * 0.1)\n",
        "    def sample(self, prob):\n",
        "        return torch.bernoulli(prob)\n",
        "    def forward(self, v):\n",
        "        h1_p = torch.sigmoid(v @ self.W1)\n",
        "        return h1_p\n",
        "if __name__ == \"__main__\":\n",
        "    vis_dim, lr, epochs = 784, 0.01, 5\n",
        "    dbm = DBM(vis_dim)\n",
        "    opt = torch.optim.Adam(dbm.parameters(), lr=lr)\n",
        "    for epoch in range(epochs):\n",
        "        data = torch.randint(0, 2, (32, vis_dim)).float()\n",
        "        h1_p = dbm(data)\n",
        "        if epoch == epochs - 1:\n",
        "            print(f\"Hidden Probabilities (h1_p) after training:\\n\", h1_p)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEEP BELEIF NETWORK (DBN)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "class DBN(nn.Module):\n",
        "    def __init__(self, layer_sizes):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([nn.Linear(layer_sizes[i], layer_sizes[i+1]) for i in range(len(layer_sizes) - 1)])\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = torch.sigmoid(layer(x))\n",
        "        return x\n",
        "    def fine_tune(self, X, y, epochs=5, lr=0.01):\n",
        "        self.fc = nn.Linear(self.layers[-1].out_features, len(torch.unique(torch.Tensor(y))))\n",
        "        opt, loss_fn = optim.Adam(self.parameters(), lr=lr), nn.CrossEntropyLoss()\n",
        "        data, targets = torch.Tensor(X), torch.LongTensor(y)\n",
        "        for epoch in range(epochs):\n",
        "            opt.zero_grad()\n",
        "            loss = loss_fn(self.fc(self(data)), targets)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        print(\"Weights after training (final layer):\")\n",
        "        print(self.fc.weight)\n",
        "layer_sizes, X_train, y_train = [784, 512, 256, 128], torch.randn(100, 784), torch.randint(0, 10, (100,))\n",
        "dbn = DBN(layer_sizes)\n",
        "dbn.fine_tune(X_train, y_train, epochs=5, lr=0.01)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbD-EiBUEBIR",
        "outputId": "22b33bcd-7eb8-4f58-8988-f9ff46a9a02d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after training (final layer):\n",
            "Parameter containing:\n",
            "tensor([[ 0.0565,  0.0402,  0.0540,  ...,  0.0549,  0.0512, -0.0398],\n",
            "        [ 0.0616, -0.0143,  0.0519,  ...,  0.0077,  0.0090, -0.0641],\n",
            "        [-0.0467, -0.0673,  0.0086,  ...,  0.0744,  0.0068,  0.0255],\n",
            "        ...,\n",
            "        [-0.0580, -0.0154, -0.0098,  ..., -0.0522,  0.0750,  0.0067],\n",
            "        [-0.0738, -0.0395,  0.0099,  ..., -0.0206,  0.0788, -0.0191],\n",
            "        [-0.0521, -0.0391, -0.0506,  ..., -0.0798, -0.0907, -0.0643]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}